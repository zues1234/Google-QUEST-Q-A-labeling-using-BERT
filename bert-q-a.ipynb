{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/bert-base-uncased/config.json\n/kaggle/input/bert-base-uncased/pytorch_model.bin\n/kaggle/input/bert-base-uncased/vocab.txt\n/kaggle/input/google-quest-challenge/sample_submission.csv\n/kaggle/input/google-quest-challenge/train.csv\n/kaggle/input/google-quest-challenge/test.csv\n","name":"stdout"}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev","execution_count":2,"outputs":[{"output_type":"stream","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  5116  100  5116    0     0  17950      0 --:--:-- --:--:-- --:--:-- 17950\nUpdating... This may take around 2 minutes.\nUpdating TPU runtime to pytorch-nightly ...\nFound existing installation: torch 1.5.0\nUninstalling torch-1.5.0:\n  Successfully uninstalled torch-1.5.0\nFound existing installation: torchvision 0.6.0a0+35d732a\nUninstalling torchvision-0.6.0a0+35d732a:\nDone updating TPU runtime\n  Successfully uninstalled torchvision-0.6.0a0+35d732a\nCopying gs://tpu-pytorch/wheels/torch-nightly-cp37-cp37m-linux_x86_64.whl...\n\\ [1 files][121.5 MiB/121.5 MiB]                                                \nOperation completed over 1 objects/121.5 MiB.                                    \nCopying gs://tpu-pytorch/wheels/torch_xla-nightly-cp37-cp37m-linux_x86_64.whl...\n\\ [1 files][128.0 MiB/128.0 MiB]                                                \nOperation completed over 1 objects/128.0 MiB.                                    \nCopying gs://tpu-pytorch/wheels/torchvision-nightly-cp37-cp37m-linux_x86_64.whl...\n/ [1 files][  4.8 MiB/  4.8 MiB]                                                \nOperation completed over 1 objects/4.8 MiB.                                      \nProcessing ./torch-nightly-cp37-cp37m-linux_x86_64.whl\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (1.18.5)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (3.7.4.1)\n\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n\u001b[31mERROR: kornia 0.3.1 has requirement torch==1.5.0, but you'll have torch 1.8.0a0 which is incompatible.\u001b[0m\n\u001b[31mERROR: allennlp 1.0.0 has requirement torch<1.6.0,>=1.5.0, but you'll have torch 1.8.0a0 which is incompatible.\u001b[0m\nInstalling collected packages: torch\nSuccessfully installed torch-1.8.0a0\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\nProcessing ./torch_xla-nightly-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-xla\nSuccessfully installed torch-xla-1.6+89b06b4\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\nProcessing ./torchvision-nightly-cp37-cp37m-linux_x86_64.whl\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (1.8.0a0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (1.18.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (7.2.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly) (3.7.4.1)\nInstalling collected packages: torchvision\nSuccessfully installed torchvision-0.9.0a0+7b9d30e\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libgfortran4 libopenblas-base\nThe following NEW packages will be installed:\n  libgfortran4 libomp5 libopenblas-base libopenblas-dev\n0 upgraded, 4 newly installed, 0 to remove and 59 not upgraded.\nNeed to get 8550 kB of archives.\nAfter this operation, 97.6 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgfortran4 amd64 7.5.0-3ubuntu1~18.04 [492 kB]\nGet:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-base amd64 0.2.20+ds-4 [3964 kB]\nGet:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-dev amd64 0.2.20+ds-4 [3860 kB]\nGet:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\nFetched 8550 kB in 1s (5745 kB/s)\ndebconf: delaying package configuration, since apt-utils is not installed\nSelecting previously unselected package libgfortran4:amd64.\n(Reading database ... 107745 files and directories currently installed.)\nPreparing to unpack .../libgfortran4_7.5.0-3ubuntu1~18.04_amd64.deb ...\nUnpacking libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\nSelecting previously unselected package libopenblas-base:amd64.\nPreparing to unpack .../libopenblas-base_0.2.20+ds-4_amd64.deb ...\nUnpacking libopenblas-base:amd64 (0.2.20+ds-4) ...\nSelecting previously unselected package libopenblas-dev:amd64.\nPreparing to unpack .../libopenblas-dev_0.2.20+ds-4_amd64.deb ...\nUnpacking libopenblas-dev:amd64 (0.2.20+ds-4) ...\nSelecting previously unselected package libomp5:amd64.\nPreparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\nUnpacking libomp5:amd64 (5.0.1-1) ...\nSetting up libomp5:amd64 (5.0.1-1) ...\nSetting up libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\nSetting up libopenblas-base:amd64 (0.2.20+ds-4) ...\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 to provide /usr/lib/x86_64-linux-gnu/libblas.so.3 (libblas.so.3-x86_64-linux-gnu) in auto mode\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so.3 to provide /usr/lib/x86_64-linux-gnu/liblapack.so.3 (liblapack.so.3-x86_64-linux-gnu) in auto mode\nSetting up libopenblas-dev:amd64 (0.2.20+ds-4) ...\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so to provide /usr/lib/x86_64-linux-gnu/libblas.so (libblas.so-x86_64-linux-gnu) in auto mode\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so to provide /usr/lib/x86_64-linux-gnu/liblapack.so (liblapack.so-x86_64-linux-gnu) in auto mode\nProcessing triggers for libc-bin (2.27-3ubuntu1) ...\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import transformers\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\nimport torch\nimport torch.nn as nn \n\nimport pandas as pd\nimport numpy as np\nfrom sklearn import model_selection\n\nimport torch_xla.core.xla_model as xm #using TPUs\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.distributed.parallel_loader as pl\nfrom scipy import stats\n\nimport pandas as pd\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BERTModel(nn.Module):\n    def __init__(self, bert_path):\n        super(BERTModel, self).__init__()\n\n        self.bert_path = bert_path\n        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n        self.bert_drop = nn.Dropout(0.3)\n        self.out = nn.Linear(768, 30)\n\n    def forward(self, ids, attention_mask , token_type_ids):\n        _, output2 = self.bert(ids, attention_mask, token_type_ids)\n        dropout = self.bert_drop(output2)\n        output = self.out(dropout)\n        return output ","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BERTdataset():\n    def __init__(self, qtitle, qbody, answer, targets, tokenizer, max_len):\n        super(BERTdataset, self).__init__()\n        self.qtitle = qtitle\n        self.qbody = qbody\n        self.answer = answer\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.answer)\n    \n    def __getitem__(self, idx):\n        title = str(self.qtitle[idx])\n        body = str(self.qbody[idx])\n        answer = str(self.answer[idx])\n\n        input = self.tokenizer.encode_plus(\n            f\"{title} {body}\",\n            answer,\n            add_special_tokens=True,\n            max_len= self.max_len \n        )\n\n        ids = input[\"input_ids\"][0:511]\n        mask = input[\"attention_mask\"][0:511]\n        token_type_ids = input[\"token_type_ids\"][0:511]\n\n        padding = int(self.max_len - len(ids))\n        \n        padded_ids = ids + ([0] * padding)\n        padded_mask = mask + ([0] * padding)\n        padded_token = token_type_ids + ([0] * padding)\n\n        return {\n            \"ids\" : torch.tensor(padded_ids, dtype=torch.long) ,\n            \"mask\" : torch.tensor(padded_mask, dtype=torch.long),\n            \"token\" : torch.tensor(padded_token, dtype=torch.long),\n            \"targets\" : torch.tensor(self.targets[idx,:][0:513], dtype= torch.float)\n        }","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return nn.BCEWithLogitsLoss()(outputs, targets)\n\n\ndef train_fn(model, dataloader, optimizer, device, scheduler=None):\n    model.train()\n    for batch_id, data in enumerate(dataloader):\n        ids = (data[\"ids\"]).to(device, dtype=torch.long)\n        mask = (data[\"mask\"]).to(device, dtype=torch.long)\n        token = (data[\"token\"]).to(device, dtype=torch.long)\n        target = (data[\"targets\"]).to(device, dtype=torch.float)\n\n        optimizer.zero_grad()\n        output = model(ids=ids, attention_mask=mask, token_type_ids=token)\n        loss = loss_fn(output, targets=target)\n        loss.backward()\n        xm.optimizer_step(optimizer)\n\n        if scheduler is not None:\n            scheduler.step()\n        \n        if batch_id % 10 == 0:\n            xm.master_print(f\"batch = {batch_id}, loss = {loss}\")\n\n\ndef eval_fn(model, dataloader, device):\n    model.eval()\n    targets=[]\n    outputs=[]\n    for batch_id, data in enumerate(dataloader):\n        ids = (data[\"ids\"]).to(device, dtype=torch.long)\n        mask = (data[\"mask\"]).to(device, dtype=torch.long)\n        token = (data[\"token\"]).to(device, dtype=torch.long)\n        target = (data[\"targets\"]).to(device, dtype=torch.float)\n\n        output = model(ids=ids, attention_mask=mask, token_type_ids=token)\n        loss = loss_fn(output, targets=target)\n\n        targets.append(target.cpu().detach().numpy())\n        outputs.append(output.cpu().detach().numpy())\n\n        target = np.vstack(targets)\n        output =  np.vstack(outputs)\n\n        return output, target","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def training(index):\n    TRAIN_BS = 16\n    MAX_LEN = 512\n    TEST_BS = 8\n    EPOCHS = 20\n    DEVICE = xm.xla_device()\n\n    df = pd.read_csv(\"../input/google-quest-challenge/train.csv\").fillna(\"none\")\n    train_df, valid_df = model_selection.train_test_split(df, test_size=0.1, random_state=45)\n    \n    train_df.reset_index(drop=True)\n    valid_df.reset_index(drop=True)\n\n    sample = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\")\n    columns = list(sample.drop(\"qa_id\", axis=1).columns)\n\n    train_targets = train_df[columns].values\n    valid_targets = valid_df[columns].values\n\n    tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")\n\n    train_dataset = BERTdataset(\n        qtitle = train_df.question_title.values,\n        qbody = train_df.question_body.values,\n        answer = train_df.answer.values,\n        targets = train_targets,\n        tokenizer= tokenizer,\n        max_len= MAX_LEN\n    )\n\n    train_sampler = torch.utils.data.DistributedSampler(\n        train_dataset,\n        num_replicas = xm.xrt_world_size(), #gets the number of devices\n        rank = xm.get_ordinal(),\n        shuffle=True\n    )\n\n    train_dataloader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size = TRAIN_BS,\n        sampler = train_sampler, #replace shuffle with sampler for multiprocessing on TPU\n    )\n\n    valid_dataset = BERTdataset(\n        qtitle = valid_df.question_title.values,\n        qbody = valid_df.question_body.values,\n        answer = valid_df.answer.values,\n        targets = valid_targets,\n        tokenizer= tokenizer,\n        max_len= MAX_LEN\n    )\n\n    valid_sampler = torch.utils.data.DistributedSampler(\n        valid_dataset,\n        num_replicas = xm.xrt_world_size(),    #gets the number of devices\n        rank = xm.get_ordinal(),\n    )\n\n    valid_dataloader = torch.utils.data.DataLoader(\n        valid_dataset,\n        batch_size = TEST_BS,\n        sampler= valid_sampler    #replace shuffle with sampler for multiprocessing on TPU\n    )\n\n    model = BERTModel(\"../input/bert-base-uncased\")\n    model.to(DEVICE)\n\n    optimizer = AdamW(model.parameters(), lr = (3e-5 * xm.xrt_world_size())) \n    num_training_steps = int((len(train_dataset)/TRAIN_BS/xm.xrt_world_size()) * EPOCHS)\n    scheduler = get_linear_schedule_with_warmup(optimizer,\n                                                num_warmup_steps = 0,\n                                                num_training_steps = num_training_steps)\n    \n    for epoch in range(EPOCHS):\n        train_pl = pl.ParallelLoader(train_dataloader, [DEVICE])\n        valid_pl = pl.ParallelLoader(valid_dataloader, [DEVICE])\n\n        train_fn(model,train_pl.per_device_loader(DEVICE),optimizer,device=DEVICE,scheduler=scheduler)\n        \n        output, target = eval_fn(model, valid_pl.per_device_loader(DEVICE),device=DEVICE)\n\n        spear=[]\n        for i in range(target.shape[1]):\n            p1 = list(target[:,i])\n            p2 = list(output[:,i])\n            coef, _ = np.nan_to_num(stats.spearmanr(p1, p2))\n            spear.append(coef)\n        spear = np.mean(spear)\n        xm.master_print(f\"epoch = {epoch}, spearman rank = {spear}\")\n        xm.save(model.state_dict(), \"./model.bin\")\n","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == \"__main__\":\n    xmp.spawn(training, nprocs=8, start_method='fork')","execution_count":47,"outputs":[{"output_type":"stream","text":"batch = 0, loss = 0.7099218964576721\nbatch = 10, loss = 0.4540395140647888\nbatch = 20, loss = 0.44330894947052\nbatch = 30, loss = 0.41578179597854614\nbatch = 40, loss = 0.3951038420200348\n","name":"stdout"},{"output_type":"stream","text":"Exception in device=TPU:2: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\nException in device=TPU:1: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n    _start_fn(index, pf_cfg, fn, args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n    fn(gindex, *args)\n  File \"<ipython-input-30-e3f4c26702b5>\", line 80, in training\n    output, target = eval_fn(model, valid_pl.per_device_loader(DEVICE),device=DEVICE)\nTraceback (most recent call last):\n  File \"<ipython-input-46-fef913b7c254>\", line 43, in eval_fn\n    output =  np.vstack(output)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n    _start_fn(index, pf_cfg, fn, args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n    fn(gindex, *args)\n  File \"<__array_function__ internals>\", line 6, in vstack\n  File \"<ipython-input-30-e3f4c26702b5>\", line 80, in training\n    output, target = eval_fn(model, valid_pl.per_device_loader(DEVICE),device=DEVICE)\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 280, in vstack\n    arrs = atleast_2d(*tup)\n  File \"<ipython-input-46-fef913b7c254>\", line 43, in eval_fn\n    output =  np.vstack(output)\n  File \"<__array_function__ internals>\", line 6, in atleast_2d\n  File \"<__array_function__ internals>\", line 6, in vstack\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 123, in atleast_2d\n    ary = asanyarray(ary)\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 280, in vstack\n    arrs = atleast_2d(*tup)\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\", line 138, in asanyarray\n    return array(a, dtype, copy=False, order=order, subok=True)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/tensor.py\", line 655, in __array__\n    return self.numpy()\nTypeError: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\nException in device=TPU:3: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\nTraceback (most recent call last):\n  File \"<__array_function__ internals>\", line 6, in atleast_2d\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n    _start_fn(index, pf_cfg, fn, args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n    fn(gindex, *args)\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 123, in atleast_2d\n    ary = asanyarray(ary)\n  File \"<ipython-input-30-e3f4c26702b5>\", line 80, in training\n    output, target = eval_fn(model, valid_pl.per_device_loader(DEVICE),device=DEVICE)\n  File \"<ipython-input-46-fef913b7c254>\", line 43, in eval_fn\n    output =  np.vstack(output)\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\", line 138, in asanyarray\n    return array(a, dtype, copy=False, order=order, subok=True)\n  File \"<__array_function__ internals>\", line 6, in vstack\n  File \"/opt/conda/lib/python3.7/site-packages/torch/tensor.py\", line 655, in __array__\n    return self.numpy()\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 280, in vstack\n    arrs = atleast_2d(*tup)\n  File \"<__array_function__ internals>\", line 6, in atleast_2d\nException in device=TPU:5: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 123, in atleast_2d\n    ary = asanyarray(ary)\nTypeError: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\nException in device=TPU:6: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\", line 138, in asanyarray\n    return array(a, dtype, copy=False, order=order, subok=True)\nException in device=TPU:4: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\nTraceback (most recent call last):\nTraceback (most recent call last):\nException in device=TPU:7: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n  File \"/opt/conda/lib/python3.7/site-packages/torch/tensor.py\", line 655, in __array__\n    return self.numpy()\nTypeError: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n    _start_fn(index, pf_cfg, fn, args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n    _start_fn(index, pf_cfg, fn, args)\nException in device=TPU:0: can't convert xla:1 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n    fn(gindex, *args)\n  File \"<ipython-input-30-e3f4c26702b5>\", line 80, in training\n    output, target = eval_fn(model, valid_pl.per_device_loader(DEVICE),device=DEVICE)\nTraceback (most recent call last):\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"<ipython-input-46-fef913b7c254>\", line 43, in eval_fn\n    output =  np.vstack(output)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n    _start_fn(index, pf_cfg, fn, args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n    _start_fn(index, pf_cfg, fn, args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 329, in _mp_start_fn\n    _start_fn(index, pf_cfg, fn, args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n    fn(gindex, *args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n    fn(gindex, *args)\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n    fn(gindex, *args)\n  File \"<ipython-input-30-e3f4c26702b5>\", line 80, in training\n    output, target = eval_fn(model, valid_pl.per_device_loader(DEVICE),device=DEVICE)\n  File \"<ipython-input-46-fef913b7c254>\", line 43, in eval_fn\n    output =  np.vstack(output)\n  File \"<ipython-input-30-e3f4c26702b5>\", line 80, in training\n    output, target = eval_fn(model, valid_pl.per_device_loader(DEVICE),device=DEVICE)\n  File \"<__array_function__ internals>\", line 6, in vstack\n  File \"<ipython-input-30-e3f4c26702b5>\", line 80, in training\n    output, target = eval_fn(model, valid_pl.per_device_loader(DEVICE),device=DEVICE)\n  File \"<ipython-input-46-fef913b7c254>\", line 43, in eval_fn\n    output =  np.vstack(output)\n  File \"<__array_function__ internals>\", line 6, in vstack\n  File \"/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\", line 323, in _start_fn\n    fn(gindex, *args)\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 280, in vstack\n    arrs = atleast_2d(*tup)\n  File \"<ipython-input-30-e3f4c26702b5>\", line 80, in training\n    output, target = eval_fn(model, valid_pl.per_device_loader(DEVICE),device=DEVICE)\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 280, in vstack\n    arrs = atleast_2d(*tup)\n  File \"<__array_function__ internals>\", line 6, in vstack\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 280, in vstack\n    arrs = atleast_2d(*tup)\n","name":"stderr"},{"output_type":"stream","text":"  File \"<ipython-input-46-fef913b7c254>\", line 43, in eval_fn\n    output =  np.vstack(output)\n  File \"<ipython-input-46-fef913b7c254>\", line 43, in eval_fn\n    output =  np.vstack(output)\n  File \"<__array_function__ internals>\", line 6, in atleast_2d\n  File \"<__array_function__ internals>\", line 6, in vstack\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 123, in atleast_2d\n    ary = asanyarray(ary)\n  File \"<__array_function__ internals>\", line 6, in atleast_2d\n  File \"<__array_function__ internals>\", line 6, in atleast_2d\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 123, in atleast_2d\n    ary = asanyarray(ary)\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 280, in vstack\n    arrs = atleast_2d(*tup)\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\", line 138, in asanyarray\n    return array(a, dtype, copy=False, order=order, subok=True)\n  File \"<__array_function__ internals>\", line 6, in atleast_2d\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\", line 138, in asanyarray\n    return array(a, dtype, copy=False, order=order, subok=True)\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 123, in atleast_2d\n    ary = asanyarray(ary)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/tensor.py\", line 655, in __array__\n    return self.numpy()\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\", line 138, in asanyarray\n    return array(a, dtype, copy=False, order=order, subok=True)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/tensor.py\", line 655, in __array__\n    return self.numpy()\nTypeError: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\", line 123, in atleast_2d\n    ary = asanyarray(ary)\nTypeError: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n  File \"/opt/conda/lib/python3.7/site-packages/torch/tensor.py\", line 655, in __array__\n    return self.numpy()\n  File \"/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py\", line 138, in asanyarray\n    return array(a, dtype, copy=False, order=order, subok=True)\nTypeError: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n  File \"/opt/conda/lib/python3.7/site-packages/torch/tensor.py\", line 655, in __array__\n    return self.numpy()\nTypeError: can't convert xla:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n","name":"stderr"},{"output_type":"error","ename":"ProcessExitedException","evalue":"process 2 terminated with exit code 17","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-538d0ab9b378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0merror_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0merror_pid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfailed_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     \u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 )\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mProcessExitedException\u001b[0m: process 2 terminated with exit code 17"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _mp_fn(index, flags):\n    torch.set_default_tensor_type('torch.FloatTensor')\n    a = training(index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"if __name__ == \"__main__\":\n    FLAGS={}\n    xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}